<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Face-Controlled Spline Scene</title>
  <script type="module">
    import { Application } from 'https://unpkg.com/@splinetool/runtime@1.9.82/build/runtime.js';

    let splineApp;
    let lep;

    async function initSpline() {
      const canvas = document.getElementById('spline-canvas');
      splineApp = new Application(canvas);
      try {
        await splineApp.load('https://prod.spline.design/abU-ltf0N5uCFYyP/scene.splinecode');
        console.log("Spline scene loaded successfully");
        // Try 'lep' first, then 'Lep'
        lep = splineApp.findObjectByName('lep') || splineApp.findObjectByName('Lep');
        console.log("Lep object found:", lep ? "Yes" : "No, lep/Lep is undefined");
        console.log("All objects in scene:", splineApp.getAllObjects().map(obj => obj.name));
        if (lep) {
          console.log("Initial lep scale:", lep.scale);
          console.log("Lep properties:", { scale: lep.scale, position: lep.position });
        }
      } catch (err) {
        console.error("Failed to load Spline scene:", err);
      }
    }

    async function requestCameraPermissions() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: {
            width: { ideal: 640 },
            height: { ideal: 480 },
            aspectRatio: { ideal: 480/640 },
            frameRate: { ideal: 15 },
            facingMode: "user"
          }
        });
        document.getElementById('video').srcObject = stream;
        console.log("Camera access granted");
      } catch (err) {
        console.error("Camera access denied:", err);
        alert("Please enable camera access for face tracking to work.");
      }
    }

    function initFaceTracking() {
      const faces = new window.FaceMesh({
        locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
      });

      faces.setOptions({
        maxNumFaces: 1,
        refineLandmarks: false,
        minDetectionConfidence: 0.1, // Lowered for maximum sensitivity
        minTrackingConfidence: 0.5
      });

      let faceDetected = false;
      let lastUpdate = Date.now();
      const debugOverlay = document.getElementById('debug-overlay');
      let originalScale = { x: 1, y: 1, z: 1 }; // Adjust if lep's default scale differs

      faces.onResults((results) => {
        if (!lep) {
          console.log("Lep object not found");
          return;
        }

        const isFaceDetected = !!results.multiFaceLandmarks[0];
        console.log("Face detected:", isFaceDetected);
        console.log("Setting overlay color:", isFaceDetected ? "green" : "red");
        debugOverlay.style.backgroundColor = isFaceDetected ? 'rgba(0, 255, 0, 0.5)' : 'rgba(255, 0, 0, 0.5)';
        lastUpdate = Date.now();

        if (isFaceDetected !== faceDetected) {
          faceDetected = isFaceDetected;
          if (faceDetected) {
            lep.setScale({ x: 0.2, y: 0.2, z: 0.2 });
            lep.position.x = 100; // Test position change
            console.log("Set scale: { x: 0.2, y: 0.2, z: 0.2 }, Position x:", lep.position.x);
          } else {
            lep.setScale(originalScale);
            lep.position.x = 0;
            console.log("Restored scale:", originalScale, "Position x:", lep.position.x);
          }
          console.log("Current lep scale:", lep.scale);
        }
      });

      // Timeout to reset overlay if no updates
      setInterval(() => {
        if (Date.now() - lastUpdate > 2000 && faceDetected) {
          console.log("No face updates for 2s, resetting");
          faceDetected = false;
          debugOverlay.style.backgroundColor = 'rgba(255, 0, 0, 0.5)';
          if (lep) {
            lep.setScale(originalScale);
            lep.position.x = 0;
            console.log("Reset scale:", originalScale, "Position x:", lep.position.x);
          }
        }
      }, 1000);

      const video = document.getElementById('video');
      const camera = new window.Camera(video, {
        onFrame: async () => await faces.send({ image: video }),
        width: 640,
        height: 480
      });

      camera.start()
        .then(() => console.log("Camera started"))
        .catch((err) => console.error("Camera failed:", err));
    }

    window.onload = async function () {
      await requestCameraPermissions();
      await initSpline();
      initFaceTracking();
    };
  </script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <style>
    body { margin: 0; overflow: hidden; display: flex; justify-content: center; align-items: center; height: 100vh; }
    #spline-canvas { width: 100%; height: 100%; display: block; }
    #video { display: none; transform: rotate(-90deg); width: 480px; height: 640px; }
    #debug-overlay { 
      position: absolute; 
      top: 10px; 
      left: 10px; 
      width: 50px; 
      height: 50px; 
      pointer-events: none; 
      z-index: 10; 
    }
  </style>
</head>
<body>
  <canvas id="spline-canvas"></canvas>
  <video id="video" autoplay playsinline></video>
  <div id="debug-overlay"></div>
</body>
</html>
