<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Face-Controlled Spline</title>
  <script type="module">
    import { Application } from 'https://unpkg.com/@splinetool/runtime@1.9.82/build/runtime.js';

    window.onload = async () => {
      // Initialize Spline
      const canvas = document.getElementById('spline-canvas');
      const app = new Application(canvas);
      await app.load('https://prod.spline.design/abU-ltf0N5uCFYyP/scene.splinecode');
      const lep = app.findObjectByName('lep');

      // Request camera access
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { width: { ideal: 640 }, height: { ideal: 480 }, aspectRatio: 480/640, frameRate: { ideal: 15 } }
        });
        document.getElementById('video').srcObject = stream;
      } catch (err) {
        alert("Camera access required for face tracking.");
        return;
      }

      // Initialize face tracking
      const faceMesh = new window.FaceMesh({
        locateFile: file => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
      });
      faceMesh.setOptions({
        maxNumFaces: 1,
        refineLandmarks: false,
        minDetectionConfidence: 0.5,
        minTrackingConfidence: 0.5
      });

      let isLooking = false;
      let stateTimeout = null;

      faceMesh.onResults(results => {
        if (!lep || !results.multiFaceLandmarks[0]) return;

        // Estimate head orientation (yaw/pitch)
        const landmarks = results.multiFaceLandmarks[0];
        const nose = landmarks[1]; // Nose tip
        const leftEye = landmarks[33]; // Left eye outer
        const rightEye = landmarks[263]; // Right eye outer

        // Adjust for portrait (-90deg rotation)
        const yaw = Math.atan2(rightEye.y - leftEye.y, rightEye.x - leftEye.x) * (180 / Math.PI);
        const pitch = Math.atan2(nose.z - (leftEye.z + rightEye.z) / 2, nose.y - (leftEye.y + rightEye.y) / 2) * (180 / Math.PI);

        // Check if looking at screen (±10°)
        const lookingAtScreen = Math.abs(yaw) < 10 && Math.abs(pitch) < 10;

        // Update Spline state only on change
        if (lookingAtScreen !== isLooking) {
          isLooking = lookingAtScreen;
          clearTimeout(stateTimeout);

          if (isLooking) {
            // Trigger state sequence: Base State -> State -> State 2
            lep.setState('Base State');
            stateTimeout = setTimeout(() => {
              lep.setState('State');
              stateTimeout = setTimeout(() => lep.setState('State 2'), 200);
            }, 200);
          } else {
            // Revert to Base State
            lep.setState('Base State');
          }
        }
      });

      // Start camera
      const video = document.getElementById('video');
      const camera = new window.Camera(video, {
        onFrame: async () => await faceMesh.send({ image: video }),
        width: 640,
        height: 480
      });
      camera.start();
    };
  </script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <style>
    body { margin: 0; overflow: hidden; display: flex; justify-content: center; align-items: center; height: 100vh; }
    #spline-canvas { width: 100%; height: 100%; }
    #video { display: none; transform: rotate(-90deg); width: 480px; height: 640px; }
  </style>
</head>
<body>
  <canvas id="spline-canvas"></canvas>
  <video id="video" autoplay playsinline></video>
</body>
</html>
